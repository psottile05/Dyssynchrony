{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from IPython.parallel import Client\n",
    "import scipy.signal as signal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "ipclient = Client()\n",
    "print (ipclient.ids)\n",
    "#ipview = ipclient[:]\n",
    "ipview = ipclient.load_balanced_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.VentDyssynchrony_db\n",
    "breath_data = db.BreathData_collection\n",
    "patient_data = db.PatientData_collection\n",
    "log_data = db.LogData_collection\n",
    "vent_data = db.VentSettings_collection\n",
    "RN_data = db.RNData_collection\n",
    "RT_data = db.RTData_collection\n",
    "Lab_data = db.LabData_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open RawData and Populate Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='E:\\Research_Data\\Vent_Dyssynchrony\\Data\\Raw_Data'\n",
    "#path='Z:\\Research_Data\\Vent_Dyssynchrony\\Data\\Raw_Data'\n",
    "#path = r'C:\\Users\\sottilep\\Documents\\Vent_Dyssynchrony\\Raw_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipview.parallel(block=True)\n",
    "def data_entry(data_files):\n",
    "    import pandas as pd\n",
    "    import scipy.stats as stats\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import datetime as dt\n",
    "    from pymongo import MongoClient\n",
    "    import pymongo\n",
    "    import sys\n",
    "    import scipy.signal as signal\n",
    "    \n",
    "    # Open Mongos for Each Engine for Parallel Inputs\n",
    "    client = MongoClient()\n",
    "    db = client.VentDyssynchrony_db\n",
    "    breath_data = db.BreathData_collection\n",
    "    patient_data = db.PatientData_collection\n",
    "    log_data = db.LogData_collection\n",
    "    vent_data = db.VentSettings_collection\n",
    "    RN_data = db.RNData_collection\n",
    "    RT_data = db.RTData_collection\n",
    "    Lab_data = db.LabData_collection\n",
    "    \n",
    "    # Define Location Function\n",
    "    def get_location(group, errors):\n",
    "        try:\n",
    "            location = int(pd.to_datetime(group.DateTime.min(), coerce=True).value)\n",
    "        except:\n",
    "            location = 0\n",
    "            errors.appends('location conversion failed')\n",
    "        return (location, errors)\n",
    "    \n",
    "    # Define Elapse Time Calculator:\n",
    "    def get_ElapseTime(df, errors):\n",
    "        try:\n",
    "            elapsetime = pd.to_timedelta(df.DateTime.max()-df.DateTime.min(), unit='s')\n",
    "        except:\n",
    "            elapsetime = 0\n",
    "            errors.append('DateTime NAT')\n",
    "            print (patients, files, df.DateTime.max(), df.DateTime.min())\n",
    "        return (elapsetime, errors)\n",
    "    \n",
    "    # Define Pressure and Flow Extrema Calculator (returns tuple(value, time, location))\n",
    "    def pres_flow_extrema(group):\n",
    "        \n",
    "        types = ['Flow (l/min)', 'Paw (cmH2O)']\n",
    "        max_flow = []\n",
    "        min_flow = []\n",
    "        max_pressure = []\n",
    "        min_pressure = []\n",
    "\n",
    "        for t in types:\n",
    "            leng = int(len(group[t]) / 15) + 1\n",
    "            max_peaks = signal.argrelmax(group[t].values, order = leng)\n",
    "            min_valleys = signal.argrelmin(group[t].values, order = leng)\n",
    "\n",
    "            if (len(max_peaks[0]) < 1 or len(min_valleys[0]) < 1):\n",
    "                max_peaks = signal.argrelmax(group[t].values, order = 1)\n",
    "                min_valleys = signal.argrelmin(group[t].values, order = 1)\n",
    "                \n",
    "            for peaks in max_peaks[0]:\n",
    "                if t == 'Flow (l/min)':\n",
    "                    max_flow.append([group['Flow (l/min)'].iloc[peaks], str(group.ElapseTime.iloc[peaks]), peaks])\n",
    "                else:\n",
    "                    max_pressure.append([group['Paw (cmH2O)'].iloc[peaks], str(group.ElapseTime.iloc[peaks]), peaks])\n",
    "            for valleys in min_valleys[0]:\n",
    "                if t == 'Flow (l/min)':\n",
    "                    min_flow.append([group['Flow (l/min)'].iloc[valleys], str(group.ElapseTime.iloc[valleys]), valleys])\n",
    "                else:\n",
    "                    min_pressure.append([group['Paw (cmH2O)'].iloc[valleys], str(group.ElapseTime.iloc[valleys]), valleys])\n",
    "\n",
    "        return (max_pressure, max_flow, min_pressure, min_flow)\n",
    "\n",
    "    # Define File Cleanup Function\n",
    "    def file_cleaner(file_path, file_type):\n",
    "        errors = []\n",
    "        \n",
    "        if file_type == 'wave' or file_type == 'breath':  \n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep = '\\t', header = 1, error_bad_lines=False, parse_dates={'DateTime':['Date', 'HH:MM:SS']},\n",
    "                                      infer_datetime_format=True, dayfirst=True, na_values = '--')\n",
    "            except:\n",
    "                errors.append('Error on CSV load')\n",
    "                print(patients, files)\n",
    "                \n",
    "            try:\n",
    "                df['DateTime'] = pd.to_datetime(df['DateTime'], dayfirst=True, infer_datetime_format=True, coerce=True)\n",
    "            except:\n",
    "                errors.append('Error in DateTime Load')\n",
    "                print(patients, files, df.DateTime, sys.exc_info()[0])\n",
    "            \n",
    "            if file_type == 'wave':\n",
    "                df['ElapseTime'] = pd.to_timedelta(df['Time(ms)'], unit='ms')\n",
    "                df.reset_index(inplace=True, drop=False)\n",
    "\n",
    "                if stats.linregress(df.index, df['Time(ms)'])[2] < 0.95:\n",
    "                    errors.append('time frame not continous, ' + 'r = ' + str(stats.linregress(df.index, df['Time(ms)'])[2]))\n",
    "                    df.plot(x='index', y='Time(ms)')\n",
    "                    plt.title(file_path)\n",
    "\n",
    "                breath_diff = np.diff(df.Breath)\n",
    "                if breath_diff.any() != 1 or 0: \n",
    "                    errors.append('breath count not continous')\n",
    "                    df.plot(x='index', y='Breath')\n",
    "                    plt.title(file_path)\n",
    "\n",
    "                df.drop(['Paux (cmH2O)', 'CO2 (mmHg)', 'Comment', 'Time(ms)'], axis=1, inplace=True)\n",
    "            \n",
    "            elif file_type == 'breath':\n",
    "                df.drop(['Flow Pattern', 'MMV (l/min)', 'ExpMinVol Lo (l/min)', 'ExpMinVol Hi (l/min)', '%MinVol (%)','Pressure Hi (cmH2O)', \n",
    "                                 'Pcontrol (cmH2O)', 'Paux/Paw', 'Int. Controller','f cmv (b/min)', 'f simv (b/min)', 'Rate Hi (b/min)', \n",
    "                                 'Oxygen Lo (%)', 'Oxygen Hi (%)', 'P0.1 (cmH2O)', 'Pinsp (cmH2O)', 'PetCO2 (mmHg)', 'SpO2 (%)', \n",
    "                                 'Pulse (l/min)', 'HLI (%)', 'Variab. Index (%)', 'Oxygen (%).1', 'Rcexp (s)', 'Rcinsp (s)', 'WOB (J/l)', \n",
    "                                 'PTP (cmH2O*s)', '!High Pressure', '!Disconn. Patient', '!Apnea', '!Low MinVol', '!High MinVol', \n",
    "                                 '!High Rate', '!General Alarm', '!Silence', '!Fail to Cycle', '!Disconn. Vent.', '!Loss of PEEP', \n",
    "                                 '!Oxygen conc.', '!Operator', '!Gas Supply', '!SpezAlarm', 'ETS (%)', 'Body Wt (kg)','I:E.1'], axis=1, inplace=True)\n",
    "                df.rename(columns={'Vt (ml)':'Set Vt', 'Peep (cmH2O)':'PEEP', 'Mode':'Vent Mode', 'f cmv (b/min)':'Set RR', 'Oxygen (%)':'FiO2'}, inplace=True)\n",
    "                df.reset_index(inplace=True, drop=False)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                if file_type == 'lab': \n",
    "                    df = pd.read_csv(path +'\\\\'+ patients +'\\\\'+ files, na_values='--', infer_datetime_format=True,\n",
    "                                     parse_dates={'DateTime':['Date/Times']}, error_bad_lines=False)\n",
    "                else: df = pd.read_csv(path +'\\\\'+ patients +'\\\\'+ files, na_values='--', infer_datetime_format=True,\n",
    "                                 parse_dates=['DateTime'], error_bad_lines=False)\n",
    "            except:\n",
    "                errors.append('Error on CSV load')\n",
    "                #df = pd.DataFame()\n",
    "                print (patients, files, sys.exc_info()[:1])\n",
    "\n",
    "            try:\n",
    "                df['DateTime'] = pd.to_datetime(df['DateTime'], infer_datetime_format=True, coerce=True)\n",
    "            except:\n",
    "                errors.append('Error in DateTime Load')\n",
    "                print(patients, files, df.DateTime, sys.exc_info()[:1]) \n",
    "            \n",
    "            df.dropna(axis = 0, how = 'all', inplace=True)\n",
    "            df.reset_index(inplace=True, drop=False)\n",
    "            \n",
    "            if file_type == 'rn':\n",
    "                try:\n",
    "                    df.drop(['Unnamed: 35', 'A-line MAP.1'], axis=1, inplace = True)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    df.rename(columns={'Set Vt (mLs)':'Set Vt', 'HOB Position':'HOB', 'PEEP (cmH20)':'PEEP', 'FIO2':'FiO2'}, inplace=True)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    df['PEEP'] = df['PEEP'].str.rstrip(' cmH2O')\n",
    "                except:\n",
    "                    pass\n",
    "                df.replace(to_replace={'Vent Mode':{'APV;CMV':'APVCMV', 'PRVC':'APVCMV', 'PSV;CPAP':'SPONT', 'CPAP':'SPONT',\n",
    "                                                'CMV':'APVCMV', 'PCMV':'PCV', 'APV':'APVCMV', 'CMV;APV':'APVCMV'}}, inplace=True)\n",
    "\n",
    "            elif file_type == 'rt':\n",
    "                try:\n",
    "                    df.drop(['Auto Flow', 'Exhaled Vt', 'Cuff Pressure','Actual Ve','Set Ve', 'Unnamed: 25', 'Spontaneous Vt'], axis=1, inplace = True)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    df['PEEP'] = df['PEEP'].str.rstrip(' cmH2O')\n",
    "                except:\n",
    "                    pass\n",
    "                df.replace(to_replace={'Vent Mode':{'APV;CMV':'APVCMV', 'PRVC':'APVCMV', 'PSV;CPAP':'SPONT', 'CPAP':'SPONT',\n",
    "                                                'CMV':'APVCMV', 'PCMV':'PCV', 'APV':'APVCMV', 'CMV;APV':'APVCMV'}}, inplace=True)\n",
    "\n",
    "            elif file_type == 'lab':\n",
    "                for head in df.columns:\n",
    "                    new_head = head.lstrip()\n",
    "                    new_head = head.lower()\n",
    "                        \n",
    "                    if '.' in head:\n",
    "                        df.rename(columns={head:new_head.split('.')[0]+new_head.split('.')[1]}, inplace=True)\n",
    "                    else:\n",
    "                        df.rename(columns={head:new_head}, inplace=True)\n",
    "                        \n",
    "                    if head == 'DateTime' or new_head == 'datetime':\n",
    "                        df.rename(columns={'datetime':'DateTime'}, inplace=True)\n",
    "        \n",
    "        try:\n",
    "            if df.DateTime.any() == np.nan: \n",
    "                errors.append('DateTime with NAN')\n",
    "        except:\n",
    "            print (patients, files, sys.exc_info()[:1])\n",
    "                  \n",
    "        return (df, errors)\n",
    "\n",
    "    # Main Loop through each file \n",
    "    for data in data_files:  \n",
    "        path = data[0]\n",
    "        patients = data[1]\n",
    "        files = data[2]\n",
    "       \n",
    "        if 'Waveform' in files:\n",
    "            df, errors = file_cleaner(path + '\\\\' + patients + '\\\\' + files, 'wave')\n",
    "            groups = df.groupby('Breath')\n",
    "            for name, group in groups:\n",
    "                \n",
    "                try:\n",
    "                    location = int(group.DateTime.astype(np.int64).min())\n",
    "                except:\n",
    "                    location = 0\n",
    "                    errors.append('location conversion failed')\n",
    "                \n",
    "                max_pressure, max_flow, min_pressure, min_flow = pres_flow_extrema(group)\n",
    "                \n",
    "                try: \n",
    "                    insp_time = group[group.Status != 0]['ElapseTime'].dt.to_pytimedelta().max().total_seconds()-group[group.Status != 0]['ElapseTime'].dt.to_pytimedelta().min().total_seconds()\n",
    "                except:\n",
    "                    insp_time = 0\n",
    "                    errors.append('could not calculate iTime: ' + str(name))\n",
    "                \n",
    "                try: \n",
    "                    breath_time = group.ElapseTime.dt.to_pytimedelta().max().total_seconds()-group.ElapseTime.dt.to_pytimedelta().min().total_seconds()\n",
    "                except:\n",
    "                    breath_time = 0\n",
    "                    errors.append('could not calculate breath_time: ' + str(name))\n",
    "        \n",
    "                data_document = {\n",
    "                            '_id': patients + '\\\\WF' + str(group.Breath.min()) +'\\\\' + str(group.DateTime.min()),\n",
    "                            'patientID': patients,\n",
    "                            'file_name': patients + '\\\\' + files,\n",
    "                            'breath_number':int(group.Breath.max()),\n",
    "                            'start_time': group.DateTime.dt.to_pydatetime().min(),  #str(group.DateTime.min())\n",
    "                            'end_time': group.DateTime.dt.to_pydatetime().max(),\n",
    "                            'location': [location, 0],\n",
    "                            'characteristics':{'breath_time':breath_time,\n",
    "                                               'insp_time': insp_time,\n",
    "                                               'exp_time': breath_time - insp_time,\n",
    "                                               'peak_pressure': group['Paw (cmH2O)'].max(),\n",
    "                                               'min_pressure':group['Paw (cmH2O)'].min(),\n",
    "                                               'peak_insp_flow': group[group.Status == 0]['Flow (l/min)'].max(),\n",
    "                                               'min_exp_flow': group[group.Status == 1]['Flow (l/min)'].max(),\n",
    "                                               'max_vol': group['Volume (ml)'].max(),\n",
    "                                               'min_vol': group['Volume (ml)'].min(),\n",
    "                                               'end_insp_vol': group[group.Status == 0]['Volume (ml)'].tail(10).min(),\n",
    "                                               'max_pressure': str(max_pressure),\n",
    "                                               'max_flow': str(max_flow),\n",
    "                                               'min_pressure': str(min_pressure), \n",
    "                                               'min_flow': str(min_flow) }, \n",
    "                            'data_frame': {'DateTime': group.DateTime.dt.to_pydatetime().tolist(),\n",
    "                                           'Time': group.ElapseTime.values.tolist(),\n",
    "                                           'Status': group.Status.values.tolist(),\n",
    "                                           'Paw': group['Paw (cmH2O)'].values.tolist(),\n",
    "                                           'Flow': group['Flow (l/min)'].values.tolist(),\n",
    "                                           'Volume': group['Volume (ml)'].values.tolist()}}  \n",
    "                \n",
    "                try:\n",
    "                    breath_data.insert(data_document)    \n",
    "                except:\n",
    "                    print(patients, files, sys.exc_info()[:1])\n",
    "            elapsetime = df.ElapseTime.max()\n",
    "        \n",
    "        elif 'Breath' in files:\n",
    "            df, errors = file_cleaner(path + '\\\\' + patients + '\\\\' + files, 'breath')\n",
    "            groups = df.groupby('index')\n",
    "            for name, group in groups:    \n",
    "                location, errors = get_location(group, errors)\n",
    "                group.dropna(axis=1, how='any', inplace=True)\n",
    "                if group.size > 0:\n",
    "                    try:\n",
    "                        data_document = {\n",
    "                            '_id': patients + '\\\\Vent' + str(group.index.min()) +'\\\\' + str(group.DateTime.min()),\n",
    "                            'patientID': patients,\n",
    "                            'file_name': patients + '\\\\' + files,\n",
    "                            'breath_number':int(group.index.max()),\n",
    "                            'breath_time': group.DateTime.dt.to_pydatetime().min(),\n",
    "                            'vent_settings': group.to_dict(orient='records'),\n",
    "                            'location': [location, 0]}\n",
    "                  \n",
    "                        try:\n",
    "                            vent_data.insert(data_document)\n",
    "                        except pymongo.errors.DuplicateKeyError:\n",
    "                            pass\n",
    "                    except:\n",
    "                        errors.append('No DateTime on Insert '+patients+'\\\\'+files+str(name))\n",
    "            elapsetime, errors = get_ElapseTime(df, errors)\n",
    "                \n",
    "        elif 'RN' in files:\n",
    "            df, errors = file_cleaner(path + '\\\\' + patients + '\\\\' + files, 'rn')\n",
    "            groups = df.groupby('index')\n",
    "            for name, group in groups:\n",
    "                location, errors = get_location(group, errors)\n",
    "                group.dropna(axis=1, how='any', inplace=True)\n",
    "                if group.size > 0:\n",
    "                    try:\n",
    "                        data_document = {\n",
    "                            '_id': patients + '\\\\RN' + str(group.index.min()) + '\\\\' + str(group.DateTime.min()),\n",
    "                            'patientID': patients,\n",
    "                            'file_name': patients + '\\\\' + files,\n",
    "                            'entry_number':int(group.index.max()),\n",
    "                            'entry_time': group.DateTime.dt.to_pydatetime().min(),\n",
    "                            'RN_entry': group.to_dict(orient='records'),\n",
    "                            'location': [location, 0]}\n",
    "                    \n",
    "                        try:\n",
    "                            RN_data.insert(data_document)\n",
    "                        except pymongo.errors.DuplicateKeyError:\n",
    "                            pass\n",
    "                    \n",
    "                    except:\n",
    "                        errors.append('Not DateTime' +patients+files)\n",
    "                    \n",
    "            elapsetime, errors = get_ElapseTime(df, errors)\n",
    "        \n",
    "        elif 'RT' in files:\n",
    "            df, errors = file_cleaner(path + '\\\\' + patients + '\\\\' + files, 'rt')\n",
    "            groups = df.groupby('index')\n",
    "            for name, group in groups: \n",
    "                location, errors = get_location(group, errors)\n",
    "                group.dropna(axis=1, how='any', inplace=True)\n",
    "                if group.size > 0:\n",
    "                    data_document = {\n",
    "                            '_id': patients + '\\\\RT' + str(group.index.min()) +'\\\\' + str(group.DateTime.min()),\n",
    "                            'patientID': patients,\n",
    "                            'file_name': patients + '\\\\' + files,\n",
    "                            'entry_number':int(group.index.max()),\n",
    "                            'entry_time': group.DateTime.dt.to_pydatetime().min(),\n",
    "                            'RT_entry': group.to_dict(orient='records'),\n",
    "                            'location': [location, 0]}\n",
    "                    try:\n",
    "                        RT_data.insert(data_document)\n",
    "                    except pymongo.errors.DuplicateKeyError:\n",
    "                        pass\n",
    "            elapsetime, errors = get_ElapseTime(df, errors)\n",
    "        \n",
    "        elif 'Lab' in files:\n",
    "            df, errors = file_cleaner(path + '\\\\' + patients + '\\\\' + files, 'lab') \n",
    "            groups = df.groupby('index')\n",
    "            for name, group in groups: \n",
    "                location, errors = get_location(group, errors)\n",
    "                group.dropna(axis=1, how='any', inplace=True)\n",
    "                if group.size > 0:\n",
    "                    data_document = {\n",
    "                            '_id': patients + '\\\\Lab' + str(group.index.min()) +'\\\\' + str(group.DateTime.min()),\n",
    "                            'patientID': patients,\n",
    "                            'file_name': patients + '\\\\' + files,\n",
    "                            'entry_number':int(group.index.max()),\n",
    "                            'entry_time': group.DateTime.dt.to_pydatetime().min(),\n",
    "                            'Lab_entry': group.to_dict(orient='records'),\n",
    "                            'location': [location, 0]}\n",
    "                    try:\n",
    "                        Lab_data.insert(data_document)\n",
    "                    except pymongo.errors.DuplicateKeyError:\n",
    "                        pass\n",
    "            elapsetime, errors = get_ElapseTime(df, errors)\n",
    "\n",
    "        \n",
    "        log_document = {\n",
    "                    '_id': patients + '\\\\' + files,\n",
    "                    'patientID': patients,\n",
    "                    'file_name': files,\n",
    "                    'update_date': dt.datetime.now(),\n",
    "                    'n_data': len(df.index),\n",
    "                    'start_time':df.DateTime.dt.to_pydatetime().min(),\n",
    "                    'end_time':df.DateTime.dt.to_pydatetime().max(),\n",
    "                    'elapse_time': elapsetime.total_seconds(),\n",
    "                    'file_errors': errors,\n",
    "                    'location': [pd.to_datetime(df.DateTime.min(), coerce=True).value, 0]}\n",
    "        log_data.insert(log_document)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir(path)\n",
    "data_files = []\n",
    "all_files = []\n",
    "\n",
    "for patients in directory:\n",
    "    file_list = os.listdir(path + '\\\\' + patients)\n",
    "\n",
    "    for files in file_list:\n",
    "        all_files.append([path, patients, files])\n",
    "        if '.txt' in files and os.path.getsize(path +'\\\\'+ patients +'\\\\'+ files) > 1024:\n",
    "            if log_data.find({'_id': patients + '\\\\' + files}).count() == 0:\n",
    "                if 'Waveform' in files or 'Breath' in files or 'edit' in files: \n",
    "                    data_files.append([path, patients, files])               \n",
    "\n",
    "df = data_entry(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['E:\\\\Research_Data\\\\Vent_Dyssynchrony\\\\Data\\\\Raw_Data',\n",
       "  'P122',\n",
       "  'editedRN Data.txt'],\n",
       " ['E:\\\\Research_Data\\\\Vent_Dyssynchrony\\\\Data\\\\Raw_Data',\n",
       "  'P122',\n",
       "  'editedRT Data.txt'],\n",
       " ['E:\\\\Research_Data\\\\Vent_Dyssynchrony\\\\Data\\\\Raw_Data',\n",
       "  'P122',\n",
       "  'editLab Data.txt']]"
      ]
     },
     "execution_count": 9,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensure Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BreathData_collection 1299170\n",
      "LabData_collection 2076\n",
      "LogData_collection 518\n",
      "PatientData_collection 21\n",
      "RNData_collection 8743\n",
      "RTData_collection 7946\n",
      "TestData_collection 20117\n",
      "ValidatedData_collection 2388\n",
      "VentSettings_collection 1370409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FiO2'"
      ]
     },
     "execution_count": 10,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "for sheets in db.collection_names(include_system_collections=False):\n",
    "    print(sheets, pymongo.collection.Collection(db, sheets).count())\n",
    "    pymongo.collection.Collection(db, sheets).ensure_index([('location', pymongo.GEO2D)],  min=0, max=1577836800000000000, name='Location')\n",
    "    pymongo.collection.Collection(db, sheets).ensure_index([('patientID', pymongo.TEXT)],  name='patientID')\n",
    "\n",
    "\n",
    "breath_data.ensure_index([('start_time', pymongo.ASCENDING)], name='StartTime')\n",
    "breath_data.ensure_index([('breath_number', pymongo.ASCENDING)], name='breath_number')\n",
    "breath_data.ensure_index([('characteristics.breath_time', pymongo.ASCENDING)], name='breath_time')\n",
    "breath_data.ensure_index([('characteristics.exp_time', pymongo.ASCENDING)], name='exp_time')\n",
    "breath_data.ensure_index([('characteristics.insp_time', pymongo.ASCENDING)], name='insp_time')\n",
    "breath_data.ensure_index([('vent_settings.vent_mode', pymongo.ASCENDING)], name='vent_mode')\n",
    "breath_data.ensure_index([('vent_settings.set_VT', pymongo.ASCENDING)], name='set_VT')\n",
    "breath_data.ensure_index([('characteristics.peak_pressure', pymongo.ASCENDING)], name='peak_pres')\n",
    "breath_data.ensure_index([('characteristics.max_vol', pymongo.ASCENDING)], name='max_vol')\n",
    "breath_data.ensure_index([('vent_settings.distance', pymongo.ASCENDING)], name='distance')\n",
    "\n",
    "vent_data.ensure_index([('vent_settings.Vent Mode', pymongo.ASCENDING)], name='Vent Mode')\n",
    "vent_data.ensure_index([('vent_settings.f total (b/min)', pymongo.ASCENDING)], name='f')\n",
    "vent_data.ensure_index([('vent_settings.PEEP', pymongo.ASCENDING)], name='PEEP')\n",
    "vent_data.ensure_index([('vent_settings.FiO2', pymongo.ASCENDING)], name='FiO2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Breath Data to Vent Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipview.parallel(block=True)\n",
    "def link_data(breaths):\n",
    "    from pymongo import MongoClient\n",
    "    import pymongo\n",
    "    import sys\n",
    "\n",
    "    # Open Mongos for Each Engine for Parallel Inputs\n",
    "    client = MongoClient()\n",
    "    db = client.VentDyssynchrony_db\n",
    "    breath_data = db.BreathData_collection\n",
    "    vent_data = db.VentSettings_collection\n",
    "    \n",
    "    for breath in breaths:\n",
    "        data = vent_data.find_one({'patientID': breath['patientID'],\n",
    "                               'vent_settings.Vent Mode': {'$exists':1},\n",
    "                               'vent_settings.f total (b/min)': {'$exists':1},\n",
    "                               'vent_settings.PEEP': {'$exists':1},\n",
    "                               'vent_settings.FiO2': {'$exists':1},\n",
    "                               'location': {'$near': breath['location']}\n",
    "                              })\n",
    "        \n",
    "  \n",
    "        if len(data)!=0:\n",
    "            #data.rewind()\n",
    "            #data = data[0]\n",
    "            distance = breath['location'][0]-data['location'][0]\n",
    "            \n",
    "            data_types = {\n",
    "                        'reference_doc': \"data['_id']\",\n",
    "                        'file_name': \"data['file_name']\",\n",
    "                        'distance': \"distance/1000000000\",\n",
    "                        'vent_mode':\"data['vent_settings'][0]['Vent Mode']\",\n",
    "                        'set_rate': \"data['vent_settings'][0]['f total (b/min)']\",\n",
    "                        'PEEP':\"data['vent_settings'][0]['PEEP']\",\n",
    "                        'FiO2': \"data['vent_settings'][0]['FiO2']\",\n",
    "                        'set_VT': \"data['vent_settings'][0]['Set Vt']\",\n",
    "                        'p_peak': \"data['vent_settings'][0]['P peak (cmH2O)']\",\n",
    "                        'p_plat': \"data['vent_settings'][0]['P plateau (cmH2O)']\",\n",
    "                        'p_mean': \"data['vent_settings'][0]['P mean (cmH2O)']\",\n",
    "                        'leak': \"data['vent_settings'][0]['Vt leak (ml)']\",\n",
    "                        'trigger': \"data['vent_settings'][0]['Trigger']\",\n",
    "                        'ramp': \"data['vent_settings'][0]['Ramp (ms)']\",\n",
    "                        'ti': \"data['vent_settings'][0]['TI (s)']\",\n",
    "                        'te': \"data['vent_settings'][0]['TE (s)']\",\n",
    "                        'ie': \"data['vent_settings'][0]['I:E']\",             \n",
    "                        'compliance': \"data['vent_settings'][0]['Cstat (ml/cmH2O)']\"}\n",
    "\n",
    "            document = {'load_errors':[]}       \n",
    "\n",
    "            for items in data_types:\n",
    "                try:\n",
    "                    document.update({items:eval(data_types[items])})\n",
    "                except KeyError:\n",
    "                    document['load_errors'].append(items)\n",
    "\n",
    "            breath_data.update({'_id':breath['_id']},\n",
    "                              {'$set':{ 'vent_settings': document\n",
    "                                }})\n",
    "        else:\n",
    "            breath_data.update({'_id':breath['_id']},\n",
    "                              {'$set':{ 'vent_settings.load_errors': 'on matching breath.txt', 'vent_settings.distance':-6000\n",
    "                                }})\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breaths = breath_data.find({'vent_settings.distance':{'$exists':0}},\n",
    "                           {'_id':1, 'patientID':1, 'file_name':1, 'start_time':1, 'end_time':1, 'breath_number':1, 'location':1}).limit(200000)\n",
    "link_data(breaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.find({'vent_settings.distance':{'$exists':0}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.DataFrame.from_csv('E:\\Research_Data\\Vent_Dyssynchrony\\Data\\Demographic Data v2.csv')\n",
    "db.drop_collection('PatientData_collection')\n",
    "date_col = ['Admission Date/Time', 'ICU Admit Date/Time', 'ICU Discharge Date/Time', 'Hospital Discharge Date/Time', \n",
    "             'Intubation Date/Time', 'Started Recording', 'End MV Date/Time']\n",
    "\n",
    "for col in date_col:\n",
    "    demo_df[col] = pd.to_datetime(demo_df[col])\n",
    "    \n",
    "demo_df.reset_index(inplace=True)\n",
    "demo_df.rename(columns={'Age':'age', 'Gender':'gender', 'Race':'race','Admission Dx':'admit_dx', \n",
    "                        'Admission Date/Time':'admit_date', 'ICU Admit Date/Time':'icu_admit_date', \n",
    "                        'ICU Discharge Date/Time':'icu_dc_time', 'Hospital Discharge Date/Time':'hospital_dc_time', \n",
    "                        'Intubation Date/Time':'intubation_date', 'Started Recording':'recording_date', 'End MV Date/Time':'extubation_date',\n",
    "                        'Vent Days':'vent_days', 'Vent Free Days':'vent_free_days', 'ICU LOS':'icu_los', 'Hospital LOS':'hosp_los',\n",
    "                        'APACHE II Score':'apache_score', 'Initial PaO2':'init_paO2', 'Initial FIO2':'init_fio2', 'P/F Ratio':'p_to_f',\n",
    "                        'CXR Appearance':'cxr', 'Discharge Location':'dc_location', 'Height(cm)':'height', 'Weight(kg)':'weight',\n",
    "                        'Hours on Vent':'hour_on_vent', 'Hours Recorded':'hours_recorded', 'Reintubated':'reintubated', 'Tracheostomy':'trach',\n",
    "                        'NMB':'nmb', 'Proned':'proned', 'iNO':'ino', 'Vasopressors':'vasopressors', 'PBW':'pbw',\n",
    "                        'Percent Recorded': 'percent_recorded', 'Percent Recorded Once Entrolled':'percent_recorded_enrolled',\n",
    "                        'Time to Enrollement':'time_to_enroll', 'Study ID':'_id'}, inplace=True)\n",
    "\n",
    "demo_df.drop(['AUDIT-C Score'], axis=1, inplace=True)\n",
    "demo_df['_id'] = demo_df['_id'].apply(lambda x: 'P' +str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P100',\n",
       " 'P101',\n",
       " 'P102',\n",
       " 'P103',\n",
       " 'P104',\n",
       " 'P105',\n",
       " 'P106',\n",
       " 'P107',\n",
       " 'P108',\n",
       " 'P109',\n",
       " 'P110',\n",
       " 'P112',\n",
       " 'P113',\n",
       " 'P114',\n",
       " 'P115',\n",
       " 'P116',\n",
       " 'P117',\n",
       " 'P118',\n",
       " 'P119',\n",
       " 'P120',\n",
       " 'P121',\n",
       " 'P122']"
      ]
     },
     "execution_count": 31,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "patient_data.insert(demo_df.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Clean-Up and Data Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Empty RT and RN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = [RN_data, RT_data]\n",
    "\n",
    "for data in data_sets:\n",
    "    if data.name == 'RNData_collection': \n",
    "        doc = 'RN_entry'\n",
    "    else: \n",
    "        doc = 'RT_entry'\n",
    "\n",
    "    results = data.find({}, {'_id':1, doc:1})\n",
    "    unique_keys = set()\n",
    "    \n",
    "    for items in results:\n",
    "        if len(items[doc][0].keys()) < 3: \n",
    "           data.remove(items['_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensure Vent_Mode Linked to Close Data Point (<10min) from Breath Data, RT Data, RN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'avg': 3209.9607423269094, '_id': 'P117', 'count': 1401}, {'avg': 2315.7755, '_id': 'P107', 'count': 2000}, {'avg': 6.8201058201058204, '_id': 'P119', 'count': 567}, {'avg': -1884.0, '_id': 'P116', 'count': 1}, {'avg': -6000.0, '_id': 'P104', 'count': 5095}, {'avg': -6818.807822172201, '_id': 'P121', 'count': 3554}, {'avg': 1398.7679045092839, '_id': 'P102', 'count': 754}, {'avg': -8035.02662627551, '_id': 'P114', 'count': 6272}]\n"
     ]
    }
   ],
   "source": [
    "print(list(breath_data.aggregate([{'$match': {'$or':[{'vent_settings.distance': {'$gte': 600}}, {'vent_settings.distance': {'$lte':-600}}]}},\n",
    "                        {'$group': {'_id': '$patientID','count': {'$sum':1}, 'avg':{'$avg':'$vent_settings.distance'}}}])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipview.parallel(block=True)\n",
    "def find_closer(results):\n",
    "    from pymongo import MongoClient\n",
    "    import pymongo\n",
    "\n",
    "    # Open Mongos for Each Engine for Parallel Inputs\n",
    "    client = MongoClient()\n",
    "    db = client.VentDyssynchrony_db\n",
    "    breath_data = db.BreathData_collection\n",
    "    RN_data = db.RNData_collection\n",
    "    RT_data = db.RTData_collection\n",
    "    \n",
    "    data_sets = [RN_data, RT_data]\n",
    "    near = []\n",
    "    for items in results:\n",
    "        \n",
    "        for data in data_sets:\n",
    "            if data.name == 'RNData_collection': \n",
    "                doc = 'RN_entry'\n",
    "            else: \n",
    "                doc = 'RT_entry'\n",
    "\n",
    "            RNRT_data = data.find({'patientID':items['patientID'], doc+'.Vent Mode':{'$exists':1}, 'location':{'$near': items['location']}}).limit(1)\n",
    "            near.append(RNRT_data.count())\n",
    "            if RNRT_data.count() != 0:\n",
    "                \n",
    "                if (RNRT_data[0]['location'][0] - items['location'][0])/1000000000 < items['vent_settings']['distance']:\n",
    "                    old_dist = items['vent_settings']['distance']\n",
    "                    breath_data.update({'_id':items['_id']},\n",
    "                              {'$set':{'vent_settings.vent_mode': RNRT_data[0][doc]['Vent Mode'], \n",
    "                                       'vent_settings.distance': (RNRT_data[0]['location'][0] - items['location'][0])/1000000000,\n",
    "                                       'vent_settings.old_distance': old_dist\n",
    "                                }})\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = breath_data.find({'$and':[{'vent_settings.old_distance':{'$exists':0}},\n",
    "                                    {'$or':[{'vent_settings.distance': {'$gte': 600}}, {'vent_settings.distance': {'$lte':-600}}]}]},\n",
    "                          {'_id':1, 'patientID':1, 'location':1, 'vent_settings.distance':1, 'vent_settings.vent_mode':1})\n",
    "\n",
    "#find_closer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0x9acab38>"
      ]
     },
     "execution_count": 20,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.aggregate([{'$match': {'vent_settings.distance': {'$exists': 1}}},\n",
    "                        {'$group': {\n",
    "                            '_id':'$patientID', \n",
    "                            'avg':{'$avg':'$vent_settings.distance'},\n",
    "                            'max':{'$max':'$vent_settings.distance'},\n",
    "                            'min':{'$min':'$vent_settings.distance'}}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0xb4db278>"
      ]
     },
     "execution_count": 21,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.aggregate([{'$match': {'vent_settings.old_distance': {'$exists': 1}}},\n",
    "                        {'$group': {'_id': '$patientID','count': {'$sum':1}}}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for Long Breaths (>10s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 22,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.find({'characteristics.breath_time':{'$gte':10}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for Small Breaths (<50cc - likely ineffective trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24383"
      ]
     },
     "execution_count": 23,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.find({'characteristics.max_vol':{'$lte':100}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for Large Breaths (>2000cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 24,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.find({'characteristics.max_vol':{'$gte':2000}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Breath Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breath_data.find({'vent_settings.breath_type':'APVCMV'}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find Double Stacked Breaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75548"
      ]
     },
     "execution_count": 25,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.find({'characteristics.breath_time':{'$lte':1.5}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.find({'characteristics.exp_time':{'$exists':0}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipview.parallel(block=True)\n",
    "def find_exp_time(results):\n",
    "    from pymongo import MongoClient\n",
    "    import pymongo\n",
    "\n",
    "    # Open Mongos for Each Engine for Parallel Inputs\n",
    "    client = MongoClient()\n",
    "    db = client.VentDyssynchrony_db\n",
    "    breath_data = db.BreathData_collection\n",
    "\n",
    "    for items in results:\n",
    "        exp_time = items['characteristics']['breath_time'] - items['characteristics']['insp_time']\n",
    "        breath_data.update({'_id':items['_id']},\n",
    "                           {'$set': {'characteristics.exp_time': exp_time}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "results = breath_data.find({'characteristics.exp_time':{'$exists':0}}).limit(100000)\n",
    "find_exp_time(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44013"
      ]
     },
     "execution_count": 29,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "breath_data.find({'characteristics.exp_time':{'$lte':0.5}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find Flow Limited Breaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find Pressure Limited Breaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find Ineffective Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breath_data.find({'characteristics.max_vol':{'$lte':100}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find Breaths with NMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Link Breaths with Recent RASS (within 30min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}