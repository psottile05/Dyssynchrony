{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'E:\\Research_Data\\Vent_Dyssynchrony\\Data\\Epic_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def data_analysis(fileName):\n",
    "    raw_data = []\n",
    "\n",
    "    data = open(fileName, 'r+')\n",
    "    text = data.read()\n",
    "    entries = re.split('\\n\\n', text)\n",
    "\n",
    "    for items in entries:\n",
    "            raw_data.append(items.strip('\\n '))\n",
    "\n",
    "    search_items = {'DateTime': {'head':'', 'pat':'(\\d\\d/\\d\\d/\\d\\d\\n \\d\\d\\d\\d)|(\\d\\d/\\d\\d/\\d\\d\\n \\d\\d:\\d\\d:\\d\\d)|(\\d\\d/\\d\\d/\\d\\d\\n \\d\\d:\\d\\d:\\d\\d:\\d\\d)'},\n",
    "                    'BP': {'head':'BP(?! )', 'pat': '\\d\\d\\d?/\\d\\d?\\d?'},\n",
    "                    'MAP': {'head':'(?!= A-line )MAP', 'pat':'\\d\\d\\d?'},\n",
    "                    'Resp':{'head':'Resp(?![a-z ])', 'pat':'\\d\\d?'},\n",
    "                    'Pulse': {'head':'Pulse', 'pat':'\\d\\d?\\d?'},\n",
    "                    'A-line': {'head':'A-line(?! MAP)', 'pat':'\\d\\d\\d?/\\d\\d?\\d?'},\n",
    "                    'A-line MAP': {'head':'A-line MAP', 'pat':'\\d\\d\\d?'},\n",
    "                    'CVP':{'head':'CVP ', 'pat': '\\d\\d?'},\n",
    "                    'SpO2': {'head':'(?!=-)SpO2(?!-)', 'pat':'\\d\\d+'},\n",
    "                    'FiO2': {'head':'FiO2', 'pat':'(\\d\\d+)|(\\d\\d\\d)'},\n",
    "                    'Vent Mode': {'head':'Vent Mode', 'pat':'(PRVC)|((?<!;)CPAP)|(PSV(?!;))|(PSV;CPAP)|(APV(?!;))|((?<!;)CMV)|(APV;CMV)'},\n",
    "                    'Set Vt': {'head':'Set Vt', 'pat':'\\d\\d\\d'},\n",
    "                    'Set RR': {'head':'Set RR', 'pat':'\\d\\d?'},\n",
    "                    'Position': {'head':'Repositioned', 'pat':'\\w+'},\n",
    "                    'RASS': {'head':'RASS Sedation Scale', 'pat':'.\\d'},\n",
    "                    'TOF': {'head':'Twitches', 'pat':'\\d' },\n",
    "                    'PEEP':{'head':'PEEP', 'pat': '\\d\\d?'},\n",
    "                    'Plat':{'head':'Static Pressure', 'pat':'\\d+'},\n",
    "                    'iNO':{'head':'NO(?!2)', 'pat': '(\\d\\d)|(0\\.\\d)'},\n",
    "                    'CPOT Tot':{'head': 'CPOT Total', 'pat':'\\d+'},\n",
    "                    'CPOT Vent':{'head':'Ventilator Compliance', 'pat':'\\d+'}}\n",
    "\n",
    "\n",
    "    found_items = {'DateTime': {'rows':0, 'values':[]},\n",
    "                    'BP': {'rows':0, 'values':[]},\n",
    "                    'MAP': {'rows':0, 'values':[]},\n",
    "                    'Pulse': {'rows':0, 'values':[]},\n",
    "                    'Resp':{'rows':0, 'values':[]},\n",
    "                    'A-line': {'rows':0, 'values':[]},\n",
    "                    'A-line MAP': {'rows':0, 'values':[]},\n",
    "                    'CVP': {'rows':0, 'values':[]},\n",
    "                    'SpO2': {'rows':0, 'values':[]},\n",
    "                    'FiO2': {'rows':0, 'values':[]},\n",
    "                    'Vent Mode': {'rows':0, 'values':[]},\n",
    "                    'Set Vt': {'rows':0, 'values':[]},\n",
    "                    'Set RR': {'rows':0, 'values':[]},\n",
    "                    'Position': {'rows':0, 'values':[]},\n",
    "                    'RASS': {'rows':0, 'values':[]},\n",
    "                    'TOF': {'rows':0, 'values':[]},\n",
    "                    'PEEP': {'rows':0, 'values':[]},\n",
    "                    'Plat': {'rows':0, 'values':[]},\n",
    "                    'iNO': {'rows':0, 'values':[]},\n",
    "                    'CPOT Tot':{'rows':0, 'values':[]},\n",
    "                    'CPOT Vent':{'rows':0, 'values':[]},}\n",
    "\n",
    "    final_data = {'DateTime':['BP', 'MAP', 'Pulse', 'A-line', 'A-line MAP', 'CVP','SpO2', 'FiO2', 'Resp', 'Vent Mode', 'Set Vt', 'Set RR', 'Position', \n",
    "                              'RASS', 'TOF', 'PEEP', 'Plat', 'iNO', 'CPOT Tot', 'CPOT Vent']}\n",
    "\n",
    "    def date_cleaner(text):\n",
    "        clean_up = text.split('\\n')\n",
    "        text = clean_up[0] + clean_up[1]\n",
    "\n",
    "        if ':' in text:\n",
    "            clean_up = text.split(':')\n",
    "            text = clean_up[0] + clean_up[1]\n",
    "        return text\n",
    "\n",
    "    count = 0\n",
    "    for items in raw_data:\n",
    "        if items == 'Vitals':\n",
    "            count = count + 1\n",
    "\n",
    "    print (count)\n",
    "\n",
    "    for items in raw_data:\n",
    "        results = re.match(search_items['DateTime']['pat'], items)\n",
    "\n",
    "        if results:\n",
    "            text = results.group(0)\n",
    "            text = date_cleaner(text)\n",
    "            found_items['DateTime']['rows'] = found_items['DateTime']['rows'] + 1\n",
    "            found_items['DateTime']['values'].append(text)\n",
    "\n",
    "    for items in search_items:\n",
    "        if items != 'DateTime':\n",
    "            for i in range(0, len(raw_data)):\n",
    "                #Match to Desired Heading\n",
    "                results = re.match(search_items[items]['head'], raw_data[i])\n",
    "\n",
    "                if results:\n",
    "                    #if positive patch, set up blank variables\n",
    "                    temp = []            #obtain surrounding data\n",
    "                    no_date = True\n",
    "                    k=i\n",
    "                    dates = []\n",
    "\n",
    "                    #update number of hits for that heading\n",
    "                    found_items[items]['rows'] = found_items[items]['rows'] + 1\n",
    "\n",
    "                    #match desired data and blanks to keep spacing in temp list\n",
    "                    for k in range(i, i+19):                   \n",
    "                        sub_results = re.match(search_items[items]['pat'], raw_data[k])\n",
    "\n",
    "                        if sub_results:\n",
    "                            temp.append(sub_results.group(0))\n",
    "                        else:\n",
    "                            temp.append(raw_data[k])\n",
    "\n",
    "                    #special management of SPO2, Resp, HR because of Epic\n",
    "                    to_pop=[]\n",
    "                    if items == 'SpO2':\n",
    "                        for y in range(0, len(temp)-1):\n",
    "                            if temp[y].isdecimal() and int(temp[y])< 90:\n",
    "                                to_pop.append(y-1)\n",
    "                        for values in to_pop[::-1]:\n",
    "                            temp.pop(values)\n",
    "                    elif items == 'Resp':\n",
    "                        for y in range(0, len(temp)-1):\n",
    "                            if temp[y].isdecimal() and int(temp[y])> 30:\n",
    "                                to_pop.append(y-1)\n",
    "                        for values in to_pop[::-1]:\n",
    "                            temp.pop(values)\n",
    "                    elif items == 'Pulse':\n",
    "                        for y in range(0, len(temp)-1):\n",
    "                            if temp[y].isdecimal() and int(temp[y])< 60:\n",
    "                                to_pop.append(y-1)\n",
    "                        for values in to_pop[::-1]:\n",
    "                            temp.pop(values)\n",
    "                            \n",
    "\n",
    "                    #find most recent set of date data to match with\n",
    "                    while no_date:\n",
    "                        date_results = re.match(search_items['DateTime']['pat'], raw_data[k])\n",
    "\n",
    "                        if date_results:\n",
    "                            for j in range (k, k-12, -1):\n",
    "                                more_dates = re.match(search_items['DateTime']['pat'], raw_data[j])\n",
    "                                if more_dates:\n",
    "                                    dates.append(date_cleaner(more_dates.group(0)))\n",
    "                            no_date=False\n",
    "\n",
    "                        k = k-1\n",
    "\n",
    "                    #print('\\t', dates[::-1], '\\n', temp)\n",
    "\n",
    "                    #zip dates and values into tuple\n",
    "                    zipped = zip(dates[::-1], temp[1:])   \n",
    "                    found_items[items]['values'].append(list(zipped))\n",
    "\n",
    "    for items in found_items:\n",
    "        if items != 'DateTime':\n",
    "            lists = list(itertools.chain(*found_items[items]['values']))\n",
    "            found_items[items]['values'] = lists\n",
    "\n",
    "    for items in found_items:\n",
    "        print (items, len(found_items[items]['values']), found_items[items]['rows']*5)\n",
    "        #print (found_items[items]['values'])\n",
    "\n",
    "    dicts = []\n",
    "    for items in final_data['DateTime']:\n",
    "        for values in found_items[items]['values']:\n",
    "            dicts.append({items:values[1], 'DateTime':values[0]})\n",
    "\n",
    "    df = pd.DataFrame.from_dict(found_items['DateTime']['values'])\n",
    "    df.rename(columns={0:'DateTime'}, inplace=True)\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    df.set_index('DateTime', inplace=True, drop=True, verify_integrity=True)\n",
    "\n",
    "    temp_df = pd.DataFrame(dicts)\n",
    "    temp_df.replace(to_replace='', value=np.nan, inplace=True)\n",
    "    temp_df.replace(to_replace='--', value=np.nan, inplace=True)\n",
    "    temp_df['DateTime'] = pd.to_datetime(temp_df['DateTime'])\n",
    "    temp_df.set_index('DateTime', inplace=True, drop=True)\n",
    "\n",
    "    temp_df.dropna(inplace=True, axis=0, how='all')\n",
    "\n",
    "    cols = temp_df.columns\n",
    "    for col in cols:\n",
    "        temp = temp_df[col]\n",
    "        temp.dropna(inplace=True)\n",
    "        temp\n",
    "        df = df.join(temp, how='left')\n",
    "\n",
    "    df.dropna(inplace=True, how='all')\n",
    "    print(df.count())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lab_analysis(fileName):\n",
    "    class labTypes:\n",
    "        def __init__ (self, dateTime, labName, labValue):\n",
    "            self.dateTime = dateTime\n",
    "            self.labName = labName\n",
    "            self.labValue = labValue\n",
    "        \n",
    "    file = open(path+'\\\\'+ fileName)\n",
    "    fileLines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    labCollection = []\n",
    "    labNames = []\n",
    "    dates = []\n",
    "    title = \"Date/Times,\"\n",
    "    \n",
    "    for lines in fileLines:\n",
    "        if re.match(r'\\d\\d?/\\d\\d?/\\d\\d\\d\\d \\d\\d:\\d\\d', lines):\n",
    "            dateTime = lines.strip()\n",
    "            \n",
    "        if re.search(r'\\w: \\d', lines):\n",
    "            lineInfo = lines.split(\": \")\n",
    "            labName = lineInfo[0]\n",
    "            \n",
    "            temp = lineInfo[1].split(\" (\")\n",
    "            labValue = temp[0]\n",
    "    \n",
    "            temp = labName.split(\",\")\n",
    "            labName = \"\"\n",
    "            labName = labName.join(temp)\n",
    "            labValue = labValue.strip()\n",
    "    \n",
    "            labCollection.append(labTypes(dateTime, labName, labValue))\n",
    "    \n",
    "            if labName not in labNames:\n",
    "                labNames.append(labName)\n",
    "    \n",
    "            if dateTime not in dates:\n",
    "                dates.append(dateTime)\n",
    "    \n",
    "    dates.sort()\n",
    "    labNames.sort()\n",
    "    \n",
    "    \n",
    "    for labs in labNames:\n",
    "        title = title + labs + \", \"\n",
    "    \n",
    "    for number in dates:\n",
    "        title = title + \"\\n\" + number + \",\"\n",
    "    \n",
    "        for items in labNames:\n",
    "            addedItem = 0\n",
    "    \n",
    "            for things in labCollection:\n",
    "                if number == things.dateTime and items == things.labName:\n",
    "                    addedItem = 1\n",
    "                    title = title + things.labValue + \",\"\n",
    "    \n",
    "            if addedItem == 0:\n",
    "                title = title + \"--,\"\n",
    "    \n",
    "    return (title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "DateTime 738 3690\n",
      "iNO 0 0\n",
      "Vent Mode 428 430\n",
      "Resp 693 695\n",
      "Pulse 743 745\n",
      "CVP 365 365\n",
      "Position 638 640\n",
      "RASS 543 545\n",
      "SpO2 738 740\n",
      "TOF 160 160\n",
      "A-line 433 435\n",
      "CPOT Tot 260 260\n",
      "FiO2 433 435\n",
      "MAP 333 335\n",
      "PEEP 433 435\n",
      "CPOT Vent 260 260\n",
      "A-line MAP 433 435\n",
      "BP 363 365\n",
      "Plat 0 0\n",
      "Set Vt 193 195\n",
      "Set RR 353 355\n",
      "did not save P122 RN Data.txt Index has duplicate keys: <class 'pandas.tseries.index.DatetimeIndex'>\n",
      "[2015-04-14 11:28:00]\n",
      "Length: 1, Freq: None, Timezone: None \n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "DateTime 697 3485\n",
      "iNO 0 0\n",
      "Vent Mode 431 435\n",
      "Resp 652 660\n",
      "Pulse 702 710\n",
      "CVP 370 370\n",
      "Position 150 150\n",
      "RASS 0 0\n",
      "SpO2 697 705\n",
      "TOF 0 0\n",
      "A-line 437 445\n",
      "CPOT Tot 0 0\n",
      "FiO2 441 445\n",
      "MAP 0 0\n",
      "PEEP 436 440\n",
      "CPOT Vent 0 0\n",
      "A-line MAP 0 0\n",
      "BP 326 330\n",
      "Plat 90 90\n",
      "Set Vt 185 185\n",
      "Set RR 361 365\n",
      "did not save P122 RT Data.txt Index has duplicate keys: <class 'pandas.tseries.index.DatetimeIndex'>\n",
      "[2015-04-14 11:28:00]\n",
      "Length: 1, Freq: None, Timezone: None \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = os.listdir(path)\n",
    "data_files = []\n",
    "all_files = []\n",
    "\n",
    "for patients in directory:\n",
    "    file_list = os.listdir(path + '\\\\' + patients)\n",
    "\n",
    "    for files in file_list:\n",
    "        all_files.append([path, patients, files])\n",
    "        if '.txt' in files and os.path.getsize(path +'\\\\'+ patients +'\\\\'+ files) > 0:\n",
    "                if ('RN' in files or 'RT' in files) and 'edit' not in files:                          \n",
    "                    if os.path.exists(path +'\\\\'+ patients +'\\\\edited'+ files) == False:\n",
    "                        try:\n",
    "                            df = data_analysis(path +'\\\\'+ patients +'\\\\'+ files)\n",
    "                            print(patients, files)\n",
    "                            print('\\n')\n",
    "                            df.to_csv(path +'\\\\'+ patients +'\\\\edited'+ files)\n",
    "                        except Exception as e:\n",
    "                            print('did not save', patients, files, e, '\\n\\n\\n')\n",
    "                if ('Lab' in files) and 'edit' not in files:\n",
    "                        df = lab_analysis('\\\\' + patients +'\\\\'+ files)\n",
    "                        newFile = open(path+ '\\\\' +patients + '\\\\edit'+ files, \"w\")\n",
    "                        newFile.write(df)\n",
    "                        newFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2569c44faf66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
